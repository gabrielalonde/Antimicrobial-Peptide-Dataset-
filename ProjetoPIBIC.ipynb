{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWi/7ehV3uLvC1H2KPx0LH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielalonde/ProjetoPIBIC/blob/main/ProjetoPIBIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trasforma arquivo CSV em FASTA"
      ],
      "metadata": {
        "id": "J41Xt2Z3g-rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "csv_nome = 'grupo+.csv'  # nome do arquivo CSV\n",
        "fasta_nome = 'grupo+.fasta'  #nome do arquivo FASTA\n",
        "with open(csv_nome, 'r') as csv_file, open(fasta_nome, 'w') as fasta_file:  #abre os arquivos\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    header = next(csv_reader) #ignora o cabeçalho\n",
        "\n",
        "    for row in csv_reader:\n",
        "        # Cabecalho das colunas do arquivo CSV\n",
        "        ID = row[0]\n",
        "        sequence = row[1]\n",
        "        atividade = row[2]\n",
        "        banco = row[3]\n",
        "        tamanho = row[4]\n",
        "\n",
        "        # escreve a sequência no arquivo FASTA\n",
        "        fasta_file.write('>' + ID + '|' + atividade + '|' + banco + '|' + tamanho + '\\n')\n",
        "        fasta_file.write(sequence + '\\n')```\n"
      ],
      "metadata": {
        "id": "COvihhyMNLp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trasforma arquivo FASTA em CSV"
      ],
      "metadata": {
        "id": "L3l-A-DShnWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TRANSFORMA UM ARQUIVO FASTA EM CSV\n",
        "import csv\n",
        "\n",
        "csv_nome = 'dados+.csv'\n",
        "fasta_nome = 'grupo+.fasta'\n",
        "csv_header = ['ID', 'sequence', 'atividade', 'banco', 'tamanho']\n",
        "\n",
        "with open(fasta_nome, 'r') as fasta_file, open(csv_nome, 'w') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(csv_header)\n",
        "\n",
        "    ID = ''\n",
        "    sequence = ''\n",
        "    atividade = ''\n",
        "    banco = ''\n",
        "    tamanho = ''\n",
        "\n",
        "    for line in fasta_file:\n",
        "        if line.startswith('>'):\n",
        "            if ID:\n",
        "                csv_writer.writerow([ID, sequence, atividade, banco, tamanho])\n",
        "\n",
        "            fields = line.strip().lstrip('>').split('|')\n",
        "            ID = fields[0]\n",
        "            atividade = fields[1]\n",
        "            banco = fields[2]\n",
        "            tamanho = fields[3]\n",
        "            sequence = ''\n",
        "        else:\n",
        "            sequence += line.strip()\n",
        "\n",
        "    csv_writer.writerow([ID, sequence, atividade, banco, tamanho])\n"
      ],
      "metadata": {
        "id": "_kPe3W1K1zBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtragem dos aminoácidos"
      ],
      "metadata": {
        "id": "tV4pdgN6eIMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('negativo.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    results = []\n",
        "    for row in csv_reader:\n",
        "        ID = row[0]\n",
        "        sequencia = row[1]\n",
        "        atividade = row[2]\n",
        "        banco = row[3]\n",
        "        tamanho = row[4]\n",
        "        if not any(x in sequencia for x in ['Abu', 'O', 'U', 'Bal', 'Nal', 'X']):\n",
        "            results.append([ID, sequencia, atividade, banco, tamanho])\n",
        "\n",
        "with open('consolidado-filtrado1.csv', mode='w', newline='') as results_file:\n",
        "    writer = csv.writer(results_file)\n",
        "    writer.writerow(['ID', 'Sequência', 'atividade','banco','tamanho'])\n",
        "    for result in results:\n",
        "        writer.writerow(result)\n"
      ],
      "metadata": {
        "id": "oVy_kpC4oVUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removendo as duplicatas"
      ],
      "metadata": {
        "id": "kt60YDfCgQzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## RETIRA AS SEQUENCIAS DUPLICADAS DE UMA MESMA COLUNA ##\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('arquivo.csv')\n",
        "df_unique = df.drop_duplicates(subset='Sequência') #REMOVE AS DUPLICATAS DA COLUNA SEQUENCIA\n",
        "df_unique.to_csv('arquivo_+sem_duplicatas.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LIDQwOiHAmkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peptide Descriptor"
      ],
      "metadata": {
        "id": "2jMOV-Rkc1Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install modlamp"
      ],
      "metadata": {
        "id": "CFTHHhb1eGUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from modlamp.descriptors import GlobalDescriptor, PeptideDescriptor\n"
      ],
      "metadata": {
        "id": "WS0yT6U9eMlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "\n",
        "with open('grupo+.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader)\n",
        "\n",
        "    # Adicionar nome as novas colunas\n",
        "    header.extend(['NetCharge', 'BomanIndex', 'HR', 'Aliphatic', 'II', 'IP', 'HM'])\n",
        "\n",
        "    # Percorrer as linhas\n",
        "    for row in reader:\n",
        "        # Extrair a sequência de peptídeo da coluna peptideo\n",
        "        peptide = row[1]\n",
        "\n",
        "        #NetCharge\n",
        "        desc = GlobalDescriptor(peptide)\n",
        "        desc.calculate_charge(ph=7.4)\n",
        "        netcharge = desc.descriptor[0][0]\n",
        "\n",
        "        #BomanIndex\n",
        "        try:\n",
        "            desc.boman_index()\n",
        "        except:\n",
        "            breakpoint()\n",
        "        bomanIndex = desc.descriptor[0][0]\n",
        "\n",
        "        #HydrophobicRatio\n",
        "        desc.hydrophobic_ratio()\n",
        "        HR = desc.descriptor[0][0]\n",
        "\n",
        "        #AliphaticIndex\n",
        "        desc.aliphatic_index()\n",
        "        al = desc.descriptor[0][0]\n",
        "\n",
        "        #InstabilityIndex\n",
        "        desc.instability_index()\n",
        "        II = desc.descriptor[0][0]\n",
        "\n",
        "        #IsoelectricPoint\n",
        "        desc.isoelectric_point()\n",
        "        IP = desc.descriptor[0][0]\n",
        "\n",
        "        #HydrophobicMoment\n",
        "        desc2 = PeptideDescriptor(peptide, \"eisenberg\")\n",
        "        desc2.calculate_moment(window=1000)\n",
        "        HM = desc2.descriptor[0][0]\n",
        "\n",
        "        row.extend([netcharge, bomanIndex, HR, al, II, IP, HM])\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "# Escrever os dados atualizados em um novo arquivo CSV\n",
        "with open('grupo+results.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(rows)  # Escrever as linhas atualizadas\n"
      ],
      "metadata": {
        "id": "UbOKP1BMDPIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}